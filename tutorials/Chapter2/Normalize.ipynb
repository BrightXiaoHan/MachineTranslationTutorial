{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 规范化\n",
    "\n",
    "在机器翻译的数据处理过程中，规范化是指对数据中的字符表示或者大小写等进行统一，具体包括符号规范化，大小写转换和中文的简繁体转化等。由于数据来源多样，不同的数据集中可能使用不同的符号标准或者大小写规范等。同一个符号，由于使用的编码不同，计算机也会认为是不同的符号或单词。此外，这种多样性会变相地导致数据中各种符号相对稀疏，增大了模型的学习负担。通过规范化，可以将功能相同的符号或者单词表示进行统一，去除其中的噪音，减小词表规模。\n",
    "\n",
    "符号规范化，主要指的是全角或者半角符号的统一。如表所示，虽然其中的百分号、字母‘A’和数字‘9’表示的含义没有变，但是在 Unicode 标准中存在不同的编码表示。因此，需要将不同的编码进行统一。在中英翻译中，通常会根据映射规则将符号全部统一成半角符号。\n",
    "\n",
    "|  字符   | Unicode 编码 16 进制  |\n",
    "|  :----:  |:----: |\n",
    "| ％  | FF05 |\n",
    "| ﹪  | FF6A |\n",
    "| %  | 25 |\n",
    "| A  | 41 |\n",
    "| 9  | 39 |\n",
    "| ９  | FF19 |\n",
    "\n",
    "这一步的原理并不复杂，主要是涉及到字符的替换，使用正则相应的正则表达式可以很容易做到。\n",
    "\n",
    "注:以下的规范化规则均来自[sacremoses](https://github.com/alvations/sacremoses)。是Moses中 [normalize-punctuation.perl](https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/normalize-punctuation.perl)脚本的一个python版本，对于大部分场景来说够用了，我们要做的是了解这些通用脚本里面做了什么，对于垂直领域的翻译，需要根据数据的特征在这些通用脚本的基础上进行增删。如果只把它当做黑盒子来用，我们就无法做定制化的开发处理。毕竟数据的清洗质量的好坏也会在很大程度上影响模型训练的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicode中统一字符的替换\n",
    "### 与引号破折号相关的字符规范化\n",
    "在英文或者其他语言中引号和破折号是有多种字符表达方式的，它们在表意方面没有任何区别，所以我们通常把它们统一进行替换，如两个单引号替换成双引号，长破折号、短破折号都替换成短破折号。\n",
    "\n",
    "|  全角字符   | 半角字符  |\n",
    "|  :----:  |:----: |\n",
    "| `„`  | `\"` |\n",
    "| `“`  |  `\"`|\n",
    "| `”` | `\"`|\n",
    "| `–` | `-` |\n",
    "| `—` | ` - ` |\n",
    "| `´`  | `'` |\n",
    "| `‘`  | `'` |\n",
    "| `‚`  | `'` |\n",
    "| `’`  | `'` |\n",
    "| `  | `'` |\n",
    "| `''`  | `\"` |\n",
    "| `''`  | `\"` |\n",
    "\n",
    "### 全角和半角字符\n",
    "主要涉及到unicode中全角、半角符号之间的转换。因为这些符号在语义上没有区别，如果是英文或者其他拉丁语系可以统一转换成半角字符，如果是中文可以也统一转换为半角字符，在translate的后处理阶段将其恢复为全角字符。可以减少这些符号在翻译时由于不统一引起的歧义，并减少词表的大小，同时也减少了后续分词时的处理复杂度（分词时不需要考虑两套符号的影响了）。\n",
    "\n",
    "|  全角字符   | 半角字符  |\n",
    "|  :----:  |:----: |\n",
    "| `，`  | `,` |\n",
    "| `。`  |  `.`|\n",
    "| `、` | `,`|\n",
    "| `”` | `\"` |\n",
    "| `“` | `\"` |\n",
    "| `∶`  | `:` |\n",
    "| `：`  | `:` |\n",
    "| `？`  | `?` |\n",
    "| `《`  | `<` |\n",
    "| `》`  | `>` |\n",
    "| `）`  | `)` |\n",
    "| `！`  | `!` |\n",
    "| `（`  | `(` |\n",
    "| `；`  | `;` |\n",
    "| `０`  | `0` |\n",
    "| `１`  | `1` |\n",
    "| `２`  | `2` |\n",
    "| `３`  | `3` |\n",
    "| `４`  | `4` |\n",
    "| `５`  | `5` |\n",
    "| `６`  | `6` |\n",
    "| `７`  | `7` |\n",
    "| `８`  | `8` |\n",
    "| `９`  | `9` |\n",
    "| `．`  | `.` |\n",
    "| `～`  | `~` |\n",
    "| `’`  | `,` |\n",
    "| `…`  | `...` |\n",
    "| `━`  | `-` |\n",
    "| `〈`  | `<` |\n",
    "| `〉`  | `>` |\n",
    "| `【`  | `[` |\n",
    "| `】`  | `]` |\n",
    "| `％`  | `%` |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7fc3e223095e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"０《１２３》 ４５６％ 【７８９】…\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mregx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mNORMALIZE_UNICODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mregx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mREPLACE_UNICODE_PUNCTUATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "NORMALIZE_UNICODE = [ # lines 37 - 50\n",
    "        (u'„', r'\"'),\n",
    "        (u'“', r'\"'),\n",
    "        (u'”', r'\"'),\n",
    "        (u'–', r'-'),\n",
    "        (u'—', r' - '),\n",
    "        (r' +', r' '),\n",
    "        (u'´', r\"'\"),\n",
    "        (u'([a-zA-Z])‘([a-zA-Z])', r\"\\g<1>'\\g<2>\"),\n",
    "        (u'([a-zA-Z])’([a-zA-Z])', r\"\\g<1>'\\g<2>\"),\n",
    "        (u'‘', r\"'\"),\n",
    "        (u'‚', r\"'\"),\n",
    "        (u'’', r\"'\"),\n",
    "        (r\"''\", r'\"'),\n",
    "        (u'´´', r'\"'),\n",
    "        (u'…', r'...'),\n",
    "    ]\n",
    "\n",
    "REPLACE_UNICODE_PUNCTUATION = [\n",
    "    (u\"，\", u\",\"),\n",
    "    (r\"。\\s*\", u\". \"),\n",
    "    (u\"、\", u\",\"),\n",
    "    (u\"”\", u'\"'),\n",
    "    (u\"“\", u'\"'),\n",
    "    (u\"∶\", u\":\"),\n",
    "    (u\"：\", u\":\"),\n",
    "    (u\"？\", u\"?\"),\n",
    "    (u\"《\", u'\"'),\n",
    "    (u\"》\", u'\"'),\n",
    "    (u\"）\", u\")\"),\n",
    "    (u\"！\", u\"!\"),\n",
    "    (u\"（\", u\"(\"),\n",
    "    (u\"；\", u\";\"),\n",
    "    (u\"」\", u'\"'),\n",
    "    (u\"「\", u'\"'),\n",
    "    (u\"０\", u\"0\"),\n",
    "    (u\"１\", u'1'),\n",
    "    (u\"２\", u\"2\"),\n",
    "    (u\"３\", u\"3\"),\n",
    "    (u\"４\", u\"4\"),\n",
    "    (u\"５\", u\"5\"),\n",
    "    (u\"６\", u\"6\"),\n",
    "    (u\"７\", u\"7\"),\n",
    "    (u\"８\", u\"8\"),\n",
    "    (u\"９\", u\"9\"),\n",
    "    (r\"．\\s*\", u\". \"),\n",
    "    (u\"～\", u\"~\"),\n",
    "    (u\"’\", u\"'\"),\n",
    "    (u\"…\", u\"...\"),\n",
    "    (u\"━\", u\"-\"),\n",
    "    (u\"〈\", u\"<\"),\n",
    "    (u\"〉\", u\">\"),\n",
    "    (u\"【\", u\"[\"),\n",
    "    (u\"】\", u\"]\"),\n",
    "    (u\"％\", u\"%\"),\n",
    "]\n",
    "\n",
    "text = \"０《１２３》 ４５６％ 【７８９】…\"\n",
    "for regx, sub in NORMALIZE_UNICODE:\n",
    "    text = re.sub(regx, sub, text)\n",
    "    \n",
    "for regx, sub in REPLACE_UNICODE_PUNCTUATION:\n",
    "    text = re.sub(regx, sub, text)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去除额外的空格\n",
    "需要处理的情况有以下几种\n",
    "\n",
    "|  情况描述  |  替换内容  | 举例  |\n",
    "|  :----:  |:----: | :----: |\n",
    "|  \\r(CR) ,将当前位置移到本行开头，会覆盖之前的内容 | 替换为空字符串 | `Hello \\rworld` -> `Hello world`|\n",
    "| 正括号前无空格 | 在正括号前添加空格 | `Hello(world)` -> `Hello (world)` | \n",
    "| 反括号后无空格 | 在反括号后添加空格 | `Hello (world)` -> `Hello (world) `| \n",
    "| 连续多个空格 | 替换为一个空格 | `Hello  world` -> `Hello world` | \n",
    "| 反括号+空格+其他符号| 将反括号与其他符号间空格去掉 | `Hello (world) .`->`Hello (world).`|\n",
    "| 正括号后有空格| 将空格去掉 | `Hello ( world)` -> `Hello (world)` |\n",
    "| 反括号前有空格| 将空格去掉 | `Hello (world )` -> `Hello (world)` |\n",
    "| 数字与百分号之间有空格 | 将空格去掉 | `20 %` -> `20%` |\n",
    "| 冒号前有空格|将空格去掉|`11 :20` -> `11:20`|\n",
    "| 分号前有空格|将空格去掉|`hello ; world` -> `hello; world`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRA_WHITESPACE = [  # lines 21 - 30\n",
    "    (r\"\\r\", r\"\"),\n",
    "    (r\"\\(\", r\" (\"),\n",
    "    (r\"\\)\", r\") \"),\n",
    "    (r\" +\", r\" \"),\n",
    "    (r\"\\) ([.!:?;,])\", r\")\\g<1>\"),\n",
    "    (r\"\\( \", r\"(\"),\n",
    "    (r\" \\)\", r\")\"),\n",
    "    (r\"(\\d) %\", r\"\\g<1>%\"),\n",
    "    (r\" :\", r\":\"),\n",
    "    (r\" ;\", r\";\"),\n",
    "]\n",
    "\n",
    "text = \"The United States in 1805 (color map)                 _Facing_     193\"\n",
    "for regx, sub in EXTRA_WHITESPACE:\n",
    "    text = re.sub(regx, sub, text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去除不间断空格（Non-breaking space）\n",
    "什么是不间断空格呢？在unicode中使用`\\u00A0`标识不间断空格。英文写作的时候，我们写的一些词组为了避免他们分开在两行导致人们阅读的时候看不懂，就要把它们写在一起，就用到了不间断空格。这里举个例子来说明。\n",
    "![NormalSpacee](assets/NormalSpace.webp)\n",
    "这里由于我们输入的是普通空格，在输入空格后将hello和world分开了。如果我们输入一个不间断空格，会怎么样呢？\n",
    "![Non-BreakingSpace.webp](assets/Non-BreakingSpace.webp)\n",
    "这种空格如果用在单词质检对分词和后续的翻译没有什么影响，但是它经常和一些符号一起出现，我们就需要将它去掉或者做其他处理。譬如`%`,`;`。\n",
    "\n",
    "|  匹配正则   | 替换  |\n",
    "|  :----:  |:----: |\n",
    "| `\\u00A0%`  | `%` |\n",
    "| `nº\\u00A0`  |  `nº `|\n",
    "| `\\u00A0:` | `:`|\n",
    "| `\\u00A0ºC` | ` ºC` |\n",
    "| `\\u00A0cm` | ` cm` |\n",
    "| `\\u00A0\\\\?`  | `?` |\n",
    "| `\\u00A0\\\\!`  | `!` |\n",
    "| `\\u00A0;`  | `;` |\n",
    "| `,\\u00A0`  | `, ` |\n",
    "\n",
    "### 规范化数字\n",
    "如果数字间存在不间断空格，用`.`进行替换。（Moses中是这么做的，这里具体什么原因我也没搞清楚，这里直接写上来）\n",
    "\n",
    "如`123\\u00A0123` -> `123.123`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HANDLE_PSEUDO_SPACES = [ # lines 59 - 67\n",
    "    (u'\\u00A0%', r'%'),\n",
    "    (u'nº\\u00A0', u'nº '),\n",
    "    (u'\\u00A0:', r':'),\n",
    "    (u'\\u00A0ºC', u' ºC'),\n",
    "    (u'\\u00A0cm', r' cm'),\n",
    "    (u'\\u00A0\\\\?', u'?'),\n",
    "    (u'\\u00A0\\\\!', u'!'),\n",
    "    (u'\\u00A0;', r';'),\n",
    "    (u',\\u00A0', r', '),\n",
    "    (r' +', r' '),\n",
    "]\n",
    "\n",
    "NORM_NUM = [(u'(\\\\d)\\u00A0(\\\\d)', r'\\g<1>.\\g<2>'),]\n",
    "\n",
    "text = \"20{PSEUDO_SPACE}%, 11{PSEUDO_SPACE}22\".format(PSEUDO_SPACE=\"\\u00A0\")\n",
    "\n",
    "for regx, sub in HANDLE_PSEUDO_SPACES:\n",
    "    text = re.sub(regx, sub, text)\n",
    "    \n",
    "for regx, sub in NORM_NUM:\n",
    "    text = re.sub(regx, sub, text)\n",
    "    \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除控制字符\n",
    "删除如控制符：LF（换行）、CR（回车）、FF（换页）、DEL（删除）、BS（退格)、BEL（振铃）等。这一步也可以在分词的时候去做。这里不再去写。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python38364bittensorflowcondaec9a8a5cf0b5432291036442c49a5e7f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
